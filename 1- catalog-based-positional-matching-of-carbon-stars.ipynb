{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nThis notebook presents the first stage of a broader project focused on analyzing carbon stars in the Galactic plane. The goal of this stage is to identify the closest stellar counterparts to a set of five known carbon stars, using positional data from near-infrared catalogs.\n\nThe data was kindly provided by **PhD. David Merlo** and includes the following components:\n\n- `Merlo2015.pdf`: an article explaining the scientific context of the project.\n- Multiple `.asc` files: raw infrared source catalogs sorted by sky coordinates. Each file corresponds to observations in a specific photometric filter (Ks, H, J, Y, Z).\n- `lista.cat`: a catalog summary file indicating the filter and observation date associated with each `.asc` file.\n- `fuentes.txt`: a list of five carbon stars (labeled s0 to s4) with their J2000 coordinates. These are the reference targets for this study.\n- Additional test files (e.g., `Ks20s0`, `Ks20s1`, etc.): preliminary measurements for visual inspection.\n\nThe main objective of this notebook is to:\n1. Load and process each `.asc` catalog file.\n2. Filter the sources to retain only stellar-type objects.\n3. Convert catalog coordinates to a uniform astrometric format.\n4. Compute the angular separation between each source and the five carbon stars.\n5. Identify and save the closest match per star per catalog.\n6. Combine all results into a unified dataset for future light curve construction.\n\nThis positional filtering and source selection step lays the foundation for the next notebook, where the temporal behavior of these stars will be modeled.\n","metadata":{}},{"cell_type":"markdown","source":"# 1. Previewing a Sample `.asc` Catalog\n\nThis block is used to load a single `.asc` file from the local directory and inspect its structure.  \nIt reads the data into a DataFrame and displays the first few rows to verify column formatting and content.\n","metadata":{}},{"cell_type":"code","source":"# Execution Protection: prevents accidental execution   \n\nrun_example = False \n\nif run_example:\n\n    # CODE: \n    \n    #from google.colab import drive\n    #drive.mount('/content/drive')\n    \n    #import os\n    #os.listdir('/content')\n    \n    import pandas as pd\n    import os\n\n    # Load a sample .asc file from the local environment\n    directory = '/content'\n    example_file = [f for f in os.listdir(directory) if f.endswith('.asc')][0]\n    df_example = pd.read_csv(os.path.join(directory, example_file), delim_whitespace=True, header=None)\n\n    # Display the first few rows to inspect structure\n    df_example.head()\n\n# Execution Protection: prevents accidental execution  \nelse:\n    print(\"Execution blocked\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T06:21:42.687428Z","iopub.execute_input":"2025-07-03T06:21:42.687789Z","iopub.status.idle":"2025-07-03T06:21:42.694863Z","shell.execute_reply.started":"2025-07-03T06:21:42.687766Z","shell.execute_reply":"2025-07-03T06:21:42.693612Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Result:\n\n\n| Row | Col0 | Col1 | Col2    | Col3 | Col4 | Col5  | Col6    | Col7  | Col8    | Col9   | Col10 | Col11 | Col12 | Col13  |\n|-----|------|------|---------|------|------|-------|---------|-------|---------|--------|-------|-------|-------|--------|\n| 0   | 12   | 15   | 53.918  | -64  | 12   | 31.52 | 5927.36 | 3.00  | 15.974  | 0.084  | 1     | 1     | 0.74  | -6.51  |\n| 1   | 12   | 16   | 14.727  | -63  | 56   | 20.69 | 3056.21 | 3.24  | 16.009  | 0.085  | 1     | 1     | 0.48  | -0.82  |\n| 2   | 12   | 16   | 2.676   | -64  | 5    | 45.83 | 4727.49 | 3.30  | 16.401  | 0.120  | 1     | -1    | 0.38  | -5.33  |\n| 3   | 12   | 16   | 2.184   | -64  | 6    | 8.31  | 4793.99 | 3.16  | 16.090  | 0.091  | 1     | 1     | 0.31  | 173.46 |\n| 4   | 12   | 15   | 54.633  | -64  | 11   | 59.09 | 5831.36 | 3.31  | 16.049  | 0.089  | 1     | 1     | 0.44  | 170.52 |\n","metadata":{}},{"cell_type":"markdown","source":"# 2. Processing Individual `.asc` Catalogs\n\nEach of the 48 `.asc` catalogs was processed individually due to memory and runtime constraints.\n\n#### Processing Strategy\n- Only rows classified as **stellar sources** (`type = -1`) were selected for further analysis.\n- The coordinates (RA and Dec, in components across columns 0–5) were converted to `SkyCoord` objects for precise angular calculations.\n- For each catalog, the closest source was identified relative to the fixed J2000 coordinates of the five carbon stars listed in `fuentes.txt`.\n- A dedicated code block was used to process each `.asc` file individually. An example is shown below.\n\n#### Column Mapping\n- **Columns 0–5**: Positional coordinates (RA/Dec, broken into components).\n- **Column 8**: Magnitude (in a specific infrared filter).\n- **Column 9**: Magnitude error.\n- **Column 11**: Source type:\n","metadata":{}},{"cell_type":"code","source":"# Execution Protection: prevents accidental execution   \n\nrun_example = False \n\nif run_example:\n\n    # CODE: \n    import pandas as pd\n    from astropy.coordinates import SkyCoord\n    import astropy.units as u\n    import os\n    from google.colab import files\n\n    # Flag to avoid accidental re-execution\n    execution_protection_flag = False\n\n    # Function to process a single .asc file\n    def process_asc_file(file_path, carbon_stars):\n        df = pd.read_csv(file_path, delim_whitespace=True, header=None)\n    \n        # Some files may lack column 7, we check for enough columns\n        if df.shape[1] >= 14:\n            # Select relevant columns\n            df_filtered = df[[0, 1, 2, 3, 4, 5, 8, 9, 11]].copy()\n\n            # Filter only stellar sources (type -1)\n            df_stars = df_filtered[df_filtered[11] == -1]\n\n            # Convert coordinates to SkyCoord\n            df_stars['coord'] = df_stars.apply(lambda row: convert_to_skycoord(row), axis=1)\n\n            # Find closest source to each carbon star\n            closest_stars = []\n            for key, star in carbon_stars.items():\n                star_coord = SkyCoord(ra=star['ra_dec'] * u.deg, dec=star['dec_dec'] * u.deg)\n                closest_star = find_closest_star(star_coord, df_stars)\n                closest_star['carbon_star_key'] = key\n                closest_stars.append(closest_star)\n\n            return closest_stars\n        else:\n            print(f\"File {file_path} ignored: not enough columns.\")\n            return []\n\n    # Convert row-based coordinates to SkyCoord object\n    def convert_to_skycoord(row):\n        ra = f\"{int(row[0])}h{int(row[1])}m{row[2]}s\"\n        dec_sign = '-' if float(row[3]) < 0 else '+'\n        dec = f\"{dec_sign}{abs(int(row[3]))}d{int(row[4])}m{row[5]}s\"\n        return SkyCoord(ra, dec, frame='icrs')\n\n    # Find the closest star to a given coordinate\n    def find_closest_star(star_coord, df):\n        df['separation'] = df['coord'].apply(lambda x: star_coord.separation(x).arcsecond)\n        return df.loc[df['separation'].idxmin()]\n\n    # Carbon stars data (J2000)\n    carbon_stars = {\n        's0': {'name': '1215-6420', 'ra': '12 15 49.6', 'dec': '-64 20 36'},\n        's1': {'name': '1216-6420', 'ra': '12 15 58.5', 'dec': '-64 20 37'},\n        's2': {'name': '1219-6423', 'ra': '12 19 16.2', 'dec': '-64 23 14'},\n        's3': {'name': '1224-6413', 'ra': '12 24 27.0', 'dec': '-64 13 15'},\n        's4': {'name': '1228-6427', 'ra': '12 28 19.4', 'dec': '-64 27 24'}\n    }\n\n    # Convert RA/Dec to decimal degrees\n    for star in carbon_stars.values():\n        coord = SkyCoord(f\"{star['ra']} {star['dec']}\", unit=(u.hourangle, u.deg))\n        star['ra_dec'] = coord.ra.deg\n        star['dec_dec'] = coord.dec.deg\n\n    # Execution confirmation\n    if not execution_protection_flag:\n        confirmation = input(\"Are you sure you want to run the processing? (y/n): \")\n        if confirmation.lower() == 'y':\n            # Upload .asc file\n            uploaded = files.upload()\n\n            # Process each uploaded file\n            for filename in uploaded.keys():\n                print(f\"Processing file: {filename}\")\n                closest_stars = process_asc_file(filename, carbon_stars)\n\n                # Save results to CSV\n                if closest_stars:\n                    output_filename = f\"{os.path.splitext(filename)[0]}_results.csv\"\n                    df_closest = pd.DataFrame(closest_stars)\n                    df_closest.to_csv(output_filename, mode='w', header=True, index=False)\n                    files.download(output_filename)\n\n                # Print results\n                for key, value in carbon_stars.items():\n                    print(f\"Closest star to {key} ({carbon_stars[key]['name']}):\")\n                    result = [star for star in closest_stars if star['carbon_star_key'] == key]\n                    if result:\n                        print(result[0])\n                    else:\n                        print(\"No result found.\")\n\n            execution_protection_flag = True\n        else:\n            print(\"Execution cancelled.\")\n    else:\n        print(\"Code already executed once. Execution protection is active.\")\n\n# Execution Protection: prevents accidental execution  \nelse:\n    print(\"Execution blocked\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T06:51:16.885390Z","iopub.execute_input":"2025-07-03T06:51:16.885713Z","iopub.status.idle":"2025-07-03T06:51:16.908022Z","shell.execute_reply.started":"2025-07-03T06:51:16.885682Z","shell.execute_reply":"2025-07-03T06:51:16.906791Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Merging Individual Results\n\nAfter processing all catalogs individually, this block:\n- Uploads each CSV with results\n- Merges them into one consolidated DataFrame\n- Exports the final table to `combined_results.csv`\n\nThis table contains, for each carbon star in each catalog:\n- Filename\n- Closest source’s magnitude and error\n\nThis merged dataset will be used in the next step to select the best overall match for each star.\n","metadata":{}},{"cell_type":"code","source":"# Execution Protection: prevents accidental execution   \n\nrun_example = False \n\nif run_example:\n\n    # CODE: \n    import pandas as pd\n    import io\n    from google.colab import files\n\n    # Upload the individual result files\n    uploaded = files.upload()\n\n    # Combine the files into a single DataFrame\n    df_list = []\n    for file_name in uploaded.keys():\n        df = pd.read_csv(io.BytesIO(uploaded[file_name]), header=0)\n        df_list.append(df)\n\n    df_combined = pd.concat(df_list, ignore_index=True)\n\n    # Save the combined DataFrame to a CSV file for review\n    df_combined.to_csv('combined_results.csv', index=False)\n    files.download('combined_results.csv')\n\n    print(\"Combined results saved as 'combined_results.csv'\")\n\n# Execution Protection: prevents accidental execution  \nelse:\n    print(\"Execution blocked\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T06:55:26.431703Z","iopub.execute_input":"2025-07-03T06:55:26.432007Z","iopub.status.idle":"2025-07-03T06:55:26.438438Z","shell.execute_reply.started":"2025-07-03T06:55:26.431983Z","shell.execute_reply":"2025-07-03T06:55:26.437641Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Selection\n\nFinally, the combined results file was processed to identify the overall closest match for each carbon star.  \nThe coordinates and the minimum angular separation for each carbon star were calculated and stored in a final DataFrame.\n","metadata":{}},{"cell_type":"code","source":"# Execution Protection: prevents accidental execution   \n\nrun_example = False \n\nif run_example:\n\n    # CODE:\n\n    import pandas as pd\n    from astropy.coordinates import SkyCoord\n    import astropy.units as u\n    from google.colab import files\n\n    # Upload the combined results file\n    uploaded = files.upload()\n\n    # Get the uploaded file name\n    file_path = list(uploaded.keys())[0]\n    print(f\"Uploaded file: {file_path}\")\n\n    # Load the combined CSV containing results from all 48 files\n    df_combined = pd.read_csv(file_path)\n\n    # Function to parse 'coord' column back into SkyCoord objects\n    def parse_skycoord(coord_str):\n        try:\n            # Clean the string and extract RA and Dec values\n            coord_str = coord_str.replace('<SkyCoord (ICRS): (ra, dec) in deg\\n    (', '').replace(')>', '')\n            ra_dec_list = coord_str.split(',')\n\n            ra = float(ra_dec_list[0].strip())\n            dec = float(ra_dec_list[1].strip())\n            return SkyCoord(ra=ra, dec=dec, unit='deg', frame='icrs')\n        except Exception as e:\n            print(f\"Error parsing coord: {coord_str} -> {e}\")\n            return None\n\n    # Convert the 'coord' column into SkyCoord objects\n    df_combined['coord'] = df_combined['coord'].apply(parse_skycoord)\n\n    # Drop rows with invalid coordinates\n    df_combined = df_combined.dropna(subset=['coord'])\n\n    # Carbon star reference data\n    carbon_stars = {\n        's0': {'name': '1215-6420', 'ra': '12 15 49.6', 'dec': '-64 20 36'},\n        's1': {'name': '1216-6420', 'ra': '12 15 58.5', 'dec': '-64 20 37'},\n        's2': {'name': '1219-6423', 'ra': '12 19 16.2', 'dec': '-64 23 14'},\n        's3': {'name': '1224-6413', 'ra': '12 24 27.0', 'dec': '-64 13 15'},\n        's4': {'name': '1228-6427', 'ra': '12 28 19.4', 'dec': '-64 27 24'}\n    }\n\n    # Convert RA/Dec to decimal degrees\n    for star in carbon_stars.values():\n        coord = SkyCoord(f\"{star['ra']} {star['dec']}\", unit=(u.hourangle, u.deg))\n        star['ra_dec'] = coord.ra.deg\n        star['dec_dec'] = coord.dec.deg\n\n    # Function to find the closest match from a DataFrame\n    def find_closest_star(star_coord, df):\n        df['separation'] = df['coord'].apply(lambda x: star_coord.separation(x).arcsecond)\n        closest_star = df.loc[df['separation'].idxmin()]\n        return closest_star\n\n    # Find the overall closest star for each carbon star\n    general_closest_stars = {}\n    for key, star in carbon_stars.items():\n        star_coord = SkyCoord(ra=star['ra_dec']*u.deg, dec=star['dec_dec']*u.deg)\n        general_closest_stars[key] = find_closest_star(star_coord, df_combined)\n\n    # Print the results\n    for key, value in general_closest_stars.items():\n        print(f\"Closest star to {key} ({carbon_stars[key]['name']}):\")\n        print(value)\n\n    # Save final results to CSV\n    output_filename = 'final_results.csv'\n    results_df = pd.DataFrame(general_closest_stars).T\n    results_df.to_csv(output_filename, index=False)\n\n    # Download the CSV file\n    files.download(output_filename)\n\n    print(f\"Final results saved as '{output_filename}'\")\n\n# Execution Protection: prevents accidental execution  \nelse:\n    print(\"Execution blocked\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T06:59:52.103120Z","iopub.execute_input":"2025-07-03T06:59:52.103792Z","iopub.status.idle":"2025-07-03T06:59:52.117172Z","shell.execute_reply.started":"2025-07-03T06:59:52.103763Z","shell.execute_reply":"2025-07-03T06:59:52.116301Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Results Table\n\n| RA (h) | RA (m) | RA (s)  | Dec (°) | Dec (') | Dec (\") | Mag    | Error | Type | Coordinates                   | Separation (arcsec) | Carbon Star |\n|--------|--------|---------|----------|----------|-----------|--------|-------|------|-------------------------------|----------------------|--------------|\n| 12     | 15     | 49.609  | -64     | 20      | 35.77     | 12.124 | 0.01  | -1   | (183.95670417, -64.34326944) | 0.2373               | s0           |\n| 12     | 15     | 58.496  | -64     | 20      | 37.36     | 11.935 | 0.01  | -1   | (183.99373333, -64.34371111) | 0.3609               | s1           |\n| 12     | 19     | 16.168  | -64     | 23      | 14.34     | 11.444 | 0.01  | -1   | (184.81736667, -64.38731667) | 0.3983               | s2           |\n| 12     | 24     | 26.992  | -64     | 13      | 14.62     | 10.964 | 0.01  | -1   | (186.11246667, -64.22072778) | 0.3836               | s3           |\n| 12     | 28     | 19.414  | -64     | 27      | 24.08     | 10.839 | 0.01  | -1   | (187.08089167, -64.45668889) | 0.1208               | s4           |\n","metadata":{}}]}